---
title: GARCH Model Implementation
author: Based on Engle (2001)
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    theme: cosmo
    highlight-style: github
execute:
  echo: true
  warning: false
jupyter: python3
---

```{python}
#| label: setup
import logging
from datetime import datetime

import numpy as np
import pandas as pd
from plotnine import (
    aes,
    element_text,
    facet_wrap,
    geom_line,
    ggplot,
    labs,
    scale_color_manual,
    theme,
    theme_minimal,
)
from scipy import stats

from src.utils import calculate_returns, fetch_stock_data, fit_garch, plot_volatility

# Configure logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


# Import our GARCH implementation functions
```

# Data Preparation

## Portfolio Composition

This portfolio consists of:
- 50% Nasdaq (^IXIC)
- 30% Dow Jones Industrial Average (^DJI)
- 20% 10-year Treasury Constant Maturity Rate (^TNX)

## Fetching Stock Data

We'll fetch the portfolio components data using our implementation function:

```{python}
#| label: fetch-data
# Parameters
symbols = ["^IXIC", "^DJI", "^TNX"]  # Nasdaq, Dow Jones, and 10-year Treasury
# Define the date range from Robert Engle's paper (2001)
# Sample period from Table 2 and Table 3: March 23, 1990 to March 23, 2000
start_date = datetime(1990, 3, 22)
end_date = datetime(2000, 3, 24)


# start_date = end_date - timedelta(days=365 * 2)  # 2 years of data
# end_date = datetime.now()


# Portfolio weights
weights = {
    "^IXIC": 0.50,  # Nasdaq
    "^DJI": 0.30,  # Dow Jones
    "^TNX": 0.20,  # 10-year Treasury
}


# Fetch data using our implementation
logger.info("Fetching data...")
prices = fetch_stock_data(symbols, start_date, end_date)

# Display the first few rows
prices.tail()

# Apparently, DJIA data is missing for 1990-1992, so we'll drop it
prices = prices.drop(columns=["^DJI"])
# ... we have to take it from somewhere else
# found it here: https://www.kaggle.com/datasets/shiveshprakash/34-year-daily-stock-data
```

```{python}
djia_prices = pd.read_csv(
    "data/dja-performance-report-daily.csv",
    index_col="Effective Date",
    parse_dates=True,
)
djia_prices = djia_prices.rename(columns={"Close Value": "^DJI"})
prices = prices.join(djia_prices["^DJI"])
```

## Calculating Returns

Next, we calculate the log returns using our implementation function:

```{python}
#| label: calculate-returns
# Calculate log returns using our implementation
returns = calculate_returns(prices)

# Display the first few rows
returns.head()

portfolio_prices = pd.Series(0, index=prices.index, dtype=float)

# Apply weights to each component
for symbol, weight in weights.items():
    # Use pandas multiplication and addition
    portfolio_prices = portfolio_prices.add(returns[symbol].multiply(weight))

# Add portfolio returns to the returns DataFrame
returns["portfolio"] = portfolio_prices

# Display the updated returns DataFrame
```

## Visualizing Price and Returns

Let's visualize both the price series and returns using plotnine:

```{python}
#| label: visualize-data
#| fig-cap: S&P 500 Price and Log Returns

# Create dataframes for plotting
price_df = pd.DataFrame({"Date": prices.index, "Price": prices.values})


# Create dataframe for returns plotting
returns_df = pd.DataFrame(returns).reset_index()
returns_df = pd.melt(
    returns_df, id_vars=["Date"], var_name="Symbol", value_name="Return"
)
```

```{python}
# Create returns plot
returns_plot = (
    ggplot(returns_df, aes(x="Date", y="Return", color="Symbol"))
    + facet_wrap("Symbol", scales="free_y")
    + geom_line(color="#FF9900")
    + labs(title="Log Returns", x="Date", y="Log Return")
    + theme(
        plot_title=element_text(size=14, face="bold"),
        axis_title=element_text(size=12),
        axis_text=element_text(size=10),
    )
)

# Display plots

print(returns_plot)
```

# GARCH Model Estimation

## Fitting the GARCH(1,1) Model

Now we'll fit a GARCH(1,1) model to the returns data using our implementation:

```{python}
#| label: fit-garch
# Fit GARCH(1,1) model using our implementation
logger.info("Fitting GARCH(1,1) model...")
results = fit_garch(returns)

# Display model summary
logger.info("\nModel Summary:")
logger.info(results.summary())
```

## Model Parameters

The GARCH(1,1) model is specified as:

$$\sigma_t^2 = \omega + \alpha_1 \varepsilon_{t-1}^2 + \beta_1 \sigma_{t-1}^2$$

where:
- $\sigma_t^2$ is the conditional variance
- $\omega$ is the constant term
- $\alpha_1$ is the ARCH effect
- $\beta_1$ is the GARCH effect
- $\varepsilon_{t-1}^2$ is the squared lagged returns
- $\sigma_{t-1}^2$ is the lagged conditional variance

Let's extract and display the model parameters:

```{python}
#| label: model-parameters
# Extract parameters
params = results.params
print("Model Parameters:")
for param, value in params.items():
    logger.info(f"{param}: {value:.6f}")
```

# Volatility Analysis

## Conditional Volatility

Let's plot the conditional volatility using our implementation:

```{python}
#| label: plot-volatility
#| fig-cap: Conditional Volatility

# Create volatility plot using our implementation
volatility_plot = plot_volatility(results, returns)
```

## Model Diagnostics

Let's examine the model residuals using plotnine:

```{python}
#| label: model-diagnostics
#| fig-cap: Standardized Residuals and Q-Q Plot

# Get standardized residuals
std_resid = results.resid / np.sqrt(results.conditional_volatility)

# Create dataframe for residuals
resid_df = pd.DataFrame({"Date": std_resid.index, "Residual": std_resid.values})

# Create residuals plot
resid_plot = (
    ggplot(resid_df, aes(x="Date", y="Residual"))
    + geom_line(color="#FF9900")
    + labs(title="Standardized Residuals", x="Date", y="Standardized Residual")
    + theme_minimal()
    + theme(
        plot_title=element_text(size=14, face="bold"),
        axis_title=element_text(size=12),
        axis_text=element_text(size=10),
    )
)

# For Q-Q plot, we need to use matplotlib as plotnine doesn't have a direct Q-Q plot
# Create a figure with two subplots
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))

# Plot residuals using plotnine
print(resid_plot)

# Q-Q plot using matplotlib
stats.probplot(std_resid, dist="norm", plot=ax2)
ax2.set_title("Q-Q Plot of Standardized Residuals")
plt.tight_layout()
plt.show()
```

# Volatility Forecasting

## Generating Forecasts

Let's generate volatility forecasts:

```{python}
#| label: forecast
# Generate forecasts
logger.info("Generating volatility forecast...")
forecast = results.forecast(horizon=5)
logger.info("\nVolatility Forecast:")
logger.info(forecast.variance.iloc[-1])
```

## Visualizing Forecasts

Let's visualize the forecast using plotnine:

```{python}
#| label: plot-forecast
#| fig-cap: Volatility Forecast

# Create dataframes for historical and forecast data
historical_df = pd.DataFrame(
    {
        "Date": returns.index[-100:],
        "Volatility": np.sqrt(results.conditional_volatility[-100:]),
        "Type": "Historical",
    }
)

forecast_dates = pd.date_range(returns.index[-1], periods=6)[1:]
forecast_df = pd.DataFrame(
    {
        "Date": forecast_dates,
        "Volatility": np.sqrt(forecast.variance.iloc[-1]),
        "Type": "Forecast",
    }
)

# Combine dataframes
combined_df = pd.concat([historical_df, forecast_df])

# Create forecast plot
forecast_plot = (
    ggplot(combined_df, aes(x="Date", y="Volatility", color="Type"))
    + geom_line()
    + labs(title="Volatility Forecast", x="Date", y="Volatility")
    + scale_color_manual(values=["#3366CC", "#FF9900"])
    + theme_minimal()
    + theme(
        plot_title=element_text(size=14, face="bold"),
        axis_title=element_text(size=12),
        axis_text=element_text(size=10),
        legend_title=element_blank(),
    )
)

# Display plot
print(forecast_plot)
```

# Conclusion

This implementation demonstrates the key components of GARCH modeling:

1. Data preparation and log returns calculation
2. GARCH(1,1) model estimation
3. Volatility analysis and visualization
4. Model diagnostics
5. Volatility forecasting

The GARCH model provides a powerful framework for modeling and forecasting financial volatility, which is essential for risk management and asset pricing.
